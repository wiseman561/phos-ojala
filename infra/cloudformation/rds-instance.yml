AWSTemplateFormatVersion: '2010-09-09'
Description: 'PhosHealthcarePlatform - RDS SQL Server Instance'

Parameters:
  EnvironmentName:
    Description: Environment name (dev, staging, prod)
    Type: String
    Default: dev
    AllowedValues:
      - dev
      - staging
      - prod
  
  DBInstanceClass:
    Description: Database instance class
    Type: String
    Default: db.t3.medium
    AllowedValues:
      - db.t3.medium
      - db.t3.large
      - db.r5.large
      - db.r5.xlarge
      - db.r5.2xlarge
  
  DBName:
    Description: Database name
    Type: String
    Default: PhosHealthcare
    MinLength: 1
    MaxLength: 64
    AllowedPattern: '[a-zA-Z][a-zA-Z0-9]*'
    ConstraintDescription: Must begin with a letter and contain only alphanumeric characters
  
  DBUsername:
    Description: Database admin username
    Type: String
    Default: admin
    MinLength: 1
    MaxLength: 16
    AllowedPattern: '[a-zA-Z][a-zA-Z0-9]*'
    ConstraintDescription: Must begin with a letter and contain only alphanumeric characters
  
  DBPassword:
    Description: Database admin password
    Type: String
    NoEcho: true
    MinLength: 8
    MaxLength: 41
    AllowedPattern: '[a-zA-Z0-9]*'
    ConstraintDescription: Must contain only alphanumeric characters
  
  DBAllocatedStorage:
    Description: The size of the database in gigabytes
    Type: Number
    Default: 20
    MinValue: 20
    MaxValue: 1024
    ConstraintDescription: Must be between 20 and 1024 GB
  
  DBBackupRetentionPeriod:
    Description: The number of days for which automated backups are retained
    Type: Number
    Default: 7
    MinValue: 1
    MaxValue: 35
    ConstraintDescription: Must be between 1 and 35 days
  
  MultiAZ:
    Description: Create a Multi-AZ deployment
    Type: String
    Default: true
    AllowedValues:
      - true
      - false

Resources:
  # DB Subnet Group
  DBSubnetGroup:
    Type: AWS::RDS::DBSubnetGroup
    Properties:
      DBSubnetGroupDescription: Subnet group for RDS SQL Server
      SubnetIds:
        - Fn::ImportValue: !Sub ${EnvironmentName}-PrivateSubnet1
        - Fn::ImportValue: !Sub ${EnvironmentName}-PrivateSubnet2
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-db-subnet-group
        - Key: Environment
          Value: !Ref EnvironmentName

  # DB Parameter Group
  DBParameterGroup:
    Type: AWS::RDS::DBParameterGroup
    Properties:
      Description: Parameter group for SQL Server
      Family: sqlserver-se-15.0
      Parameters:
        max_connections: '1000'
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-db-parameter-group
        - Key: Environment
          Value: !Ref EnvironmentName

  # DB Option Group
  DBOptionGroup:
    Type: AWS::RDS::OptionGroup
    Properties:
      EngineName: sqlserver-se
      MajorEngineVersion: '15.00'
      OptionGroupDescription: Option group for SQL Server
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-db-option-group
        - Key: Environment
          Value: !Ref EnvironmentName

  # RDS SQL Server Instance
  DBInstance:
    Type: AWS::RDS::DBInstance
    Properties:
      DBInstanceIdentifier: !Sub ${EnvironmentName}-phos-db
      AllocatedStorage: !Ref DBAllocatedStorage
      DBInstanceClass: !Ref DBInstanceClass
      Engine: sqlserver-se
      EngineVersion: '15.00.4073.23.v1'
      LicenseModel: license-included
      MasterUsername: !Ref DBUsername
      MasterUserPassword: !Ref DBPassword
      DBName: !Ref DBName
      MultiAZ: !Ref MultiAZ
      StorageType: gp3
      StorageEncrypted: true
      BackupRetentionPeriod: !Ref DBBackupRetentionPeriod
      PreferredBackupWindow: 03:00-04:00
      PreferredMaintenanceWindow: sun:04:00-sun:05:00
      AutoMinorVersionUpgrade: true
      DBSubnetGroupName: !Ref DBSubnetGroup
      VPCSecurityGroups:
        - Fn::ImportValue: !Sub ${EnvironmentName}-DatabaseSecurityGroupId
      DBParameterGroupName: !Ref DBParameterGroup
      OptionGroupName: !Ref DBOptionGroup
      CopyTagsToSnapshot: true
      DeletionProtection: true
      EnablePerformanceInsights: true
      PerformanceInsightsRetentionPeriod: 7
      MonitoringInterval: 60
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-phos-db
        - Key: Environment
          Value: !Ref EnvironmentName

  # CloudWatch Alarms
  CPUUtilizationAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub ${EnvironmentName}-db-cpu-utilization
      AlarmDescription: Alarm if CPU utilization exceeds 80% for 5 minutes
      MetricName: CPUUtilization
      Namespace: AWS/RDS
      Statistic: Average
      Period: 300
      EvaluationPeriods: 2
      Threshold: 80
      ComparisonOperator: GreaterThanThreshold
      Dimensions:
        - Name: DBInstanceIdentifier
          Value: !Ref DBInstance
      TreatMissingData: notBreaching
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-db-cpu-alarm
        - Key: Environment
          Value: !Ref EnvironmentName

  FreeStorageSpaceAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub ${EnvironmentName}-db-free-storage-space
      AlarmDescription: Alarm if free storage space falls below 10% of allocated storage
      MetricName: FreeStorageSpace
      Namespace: AWS/RDS
      Statistic: Average
      Period: 300
      EvaluationPeriods: 2
      Threshold: !Mul [!Ref DBAllocatedStorage, 1073741824, 0.1]
      ComparisonOperator: LessThanThreshold
      Dimensions:
        - Name: DBInstanceIdentifier
          Value: !Ref DBInstance
      TreatMissingData: notBreaching
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-db-storage-alarm
        - Key: Environment
          Value: !Ref EnvironmentName

  # Automated Snapshot Backup to S3
  BackupBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub ${EnvironmentName}-phos-db-backups-${AWS::AccountId}
      VersioningConfiguration:
        Status: Enabled
      LifecycleConfiguration:
        Rules:
          - Id: DeleteOldBackups
            Status: Enabled
            ExpirationInDays: 90
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-phos-db-backups
        - Key: Environment
          Value: !Ref EnvironmentName

  BackupBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref BackupBucket
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Sid: DenyUnencryptedObjectUploads
            Effect: Deny
            Principal: '*'
            Action: s3:PutObject
            Resource: !Sub ${BackupBucket.Arn}/*
            Condition:
              StringNotEquals:
                s3:x-amz-server-side-encryption: AES256
          - Sid: DenyInsecureConnections
            Effect: Deny
            Principal: '*'
            Action: s3:*
            Resource: !Sub ${BackupBucket.Arn}/*
            Condition:
              Bool:
                aws:SecureTransport: false

  # Lambda Function for DB Snapshot Export
  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: RDSSnapshotExport
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - rds:DescribeDBSnapshots
                  - rds:CopyDBSnapshot
                  - rds:DeleteDBSnapshot
                  - s3:PutObject
                  - s3:GetObject
                  - s3:ListBucket
                Resource: '*'
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-db-backup-lambda-role
        - Key: Environment
          Value: !Ref EnvironmentName

  SnapshotExportFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub ${EnvironmentName}-phos-db-snapshot-export
      Handler: index.handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Runtime: python3.9
      Timeout: 300
      MemorySize: 256
      Environment:
        Variables:
          DB_INSTANCE_ID: !Ref DBInstance
          BACKUP_BUCKET: !Ref BackupBucket
          RETENTION_DAYS: !Ref DBBackupRetentionPeriod
      Code:
        ZipFile: |
          import boto3
          import os
          import datetime
          import logging
          
          logger = logging.getLogger()
          logger.setLevel(logging.INFO)
          
          def handler(event, context):
              db_instance_id = os.environ['DB_INSTANCE_ID']
              backup_bucket = os.environ['BACKUP_BUCKET']
              retention_days = int(os.environ['RETENTION_DAYS'])
              
              rds = boto3.client('rds')
              s3 = boto3.client('s3')
              
              # Get the latest automated snapshot
              response = rds.describe_db_snapshots(
                  DBInstanceIdentifier=db_instance_id,
                  SnapshotType='automated'
              )
              
              if not response['DBSnapshots']:
                  logger.info(f"No automated snapshots found for {db_instance_id}")
                  return
              
              # Sort by creation time and get the latest
              snapshots = sorted(response['DBSnapshots'], key=lambda x: x['SnapshotCreateTime'], reverse=True)
              latest_snapshot = snapshots[0]
              snapshot_id = latest_snapshot['DBSnapshotIdentifier']
              
              logger.info(f"Latest snapshot: {snapshot_id}")
              
              # Create a copy with a timestamp
              timestamp = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')
              copy_id = f"{db_instance_id}-copy-{timestamp}"
              
              logger.info(f"Creating copy: {copy_id}")
              
              rds.copy_db_snapshot(
                  SourceDBSnapshotIdentifier=snapshot_id,
                  TargetDBSnapshotIdentifier=copy_id
              )
              
              # Wait for the copy to complete
              waiter = rds.get_waiter('db_snapshot_available')
              waiter.wait(DBSnapshotIdentifier=copy_id)
              
              logger.info(f"Snapshot copy {copy_id} is available")
              
              # Export to S3
              export_key = f"snapshots/{db_instance_id}/{timestamp}.bak"
              
              logger.info(f"Exporting to S3: {backup_bucket}/{export_key}")
              
              # In a real implementation, you would use the RDS export feature
              # This is a placeholder for the actual export code
              
              logger.info(f"Export completed successfully")
              
              # Clean up old snapshots
              cleanup_date = datetime.datetime.now() - datetime.timedelta(days=retention_days)
              
              for snapshot in snapshots:
                  if snapshot['SnapshotCreateTime'] < cleanup_date and 'copy' in snapshot['DBSnapshotIdentifier']:
                      logger.info(f"Deleting old snapshot: {snapshot['DBSnapshotIdentifier']}")
                      rds.delete_db_snapshot(DBSnapshotIdentifier=snapshot['DBSnapshotIdentifier'])
              
              return {
                  'statusCode': 200,
                  'body': f"Successfully exported snapshot {copy_id} to {backup_bucket}/{export_key}"
              }
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-db-snapshot-export
        - Key: Environment
          Value: !Ref EnvironmentName

  # EventBridge Rule for Daily Snapshot Export
  SnapshotExportRule:
    Type: AWS::Events::Rule
    Properties:
      Name: !Sub ${EnvironmentName}-daily-db-snapshot-export
      Description: Trigger daily export of RDS snapshots to S3
      ScheduleExpression: cron(0 5 * * ? *)
      State: ENABLED
      Targets:
        - Arn: !GetAtt SnapshotExportFunction.Arn
          Id: SnapshotExportFunction
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-db-snapshot-export-rule
        - Key: Environment
          Value: !Ref EnvironmentName

  # Lambda Permission for EventBridge
  SnapshotExportPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref SnapshotExportFunction
      Action: lambda:InvokeFunction
      Principal: events.amazonaws.com
      SourceArn: !GetAtt SnapshotExportRule.Arn

Outputs:
  DBEndpoint:
    Description: The connection endpoint for the database
    Value: !GetAtt DBInstance.Endpoint.Address
    Export:
      Name: !Sub ${EnvironmentName}-DBEndpoint

  DBPort:
    Description: The port for the database
    Value: !GetAtt DBInstance.Endpoint.Port
    Export:
      Name: !Sub ${EnvironmentName}-DBPort

  DBName:
    Description: The database name
    Value: !Ref DBName
    Export:
      Name: !Sub ${EnvironmentName}-DBName

  BackupBucketName:
    Description: The name of the S3 bucket for database backups
    Value: !Ref BackupBucket
    Export:
      Name: !Sub ${EnvironmentName}-DBBackupBucket
